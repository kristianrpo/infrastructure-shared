name: Destroy Shared Infrastructure

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type EXACTLY: DESTROY SHARED to confirm'
        required: true
        default: ''

permissions:
  contents: read

env:
  TF_BACKEND_BUCKET: ${{ secrets.TF_BACKEND_BUCKET }}
  TF_BACKEND_KEY: shared/terraform.tfstate
  TF_BACKEND_REGION: ${{ secrets.AWS_REGION }}
  TF_BACKEND_DDB_TABLE: ${{ secrets.TF_BACKEND_DDB_TABLE }}

jobs:
  destroy-shared:
    name: Destroy Shared Infrastructure
    runs-on: ubuntu-latest
    steps:
      - name: Confirm destruction
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "DESTROY SHARED" ]; then
            echo "Confirmation failed. You must type EXACTLY: DESTROY SHARED"
            exit 1
          fi
          echo "Confirmation OK"

      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: terraform
        run: |
          terraform init -input=false \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="key=$TF_BACKEND_KEY" \
            -backend-config="region=$TF_BACKEND_REGION" \
            -backend-config="dynamodb_table=$TF_BACKEND_DDB_TABLE"

      - name: Get DynamoDB Table Name
        working-directory: terraform
        id: get_table
        continue-on-error: true
        run: |
          TABLE_NAME=$(terraform output -raw rabbitmq_processed_messages_table_name 2>/dev/null || echo "")
          if [ -n "$TABLE_NAME" ]; then
            echo "TABLE_NAME=$TABLE_NAME" >> $GITHUB_ENV
          else
            echo "No table found or already destroyed"
            echo "TABLE_NAME=" >> $GITHUB_ENV
          fi

      - name: Disable PITR before Destroy
        if: env.TABLE_NAME != ''
        run: |
          echo "Disabling Point-in-time Recovery for DynamoDB table: $TABLE_NAME"
          aws dynamodb update-continuous-backups \
            --table-name "$TABLE_NAME" \
            --point-in-time-recovery-specification PointInTimeRecoveryEnabled=false \
            --region ${{ secrets.AWS_REGION }} || echo "Could not disable PITR (table might not exist or already disabled)"
          
          # Wait a moment for the change to propagate
          sleep 2

      - name: Delete Grafana Ingress (to remove ALB before VPC)
        continue-on-error: true
        run: |
          echo "Deleting Grafana Ingress to remove ALB before destroying VPC..."
          
          # Configure kubectl
          CLUSTER_NAME=$(cd terraform && terraform output -raw cluster_name 2>/dev/null || echo "")
          if [ -z "$CLUSTER_NAME" ]; then
            echo "No cluster found, skipping ingress deletion"
            exit 0
          fi
          
          # Update kubeconfig
          if ! aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name "$CLUSTER_NAME" 2>/dev/null; then
            echo "Could not connect to cluster, skipping ingress deletion"
            exit 0
          fi
          
          # Delete Grafana Ingress if exists
          kubectl delete ingress grafana-ingress -n monitoring 2>/dev/null || echo "Grafana Ingress not found"
          
          # Wait for ALB to start deleting
          echo "Waiting for ALB deletion..."
          sleep 30

      - name: Terraform Destroy
        working-directory: terraform
        run: terraform destroy -auto-approve

      - name: Delete S3 backend bucket (with all objects and versions)
        run: |
          echo "Deleting all objects and versions from S3 bucket: $TF_BACKEND_BUCKET"
          
          # Delete all object versions (for versioned buckets)
          aws s3api list-object-versions \
            --bucket "$TF_BACKEND_BUCKET" \
            --output json > /tmp/versions.json || echo "No objects to delete"
          
          # Delete all versions and delete markers
          if [ -f /tmp/versions.json ]; then
            cat /tmp/versions.json | jq -r '.Versions[]? | "\(.Key)|\(.VersionId)"' | while read line; do
              KEY=$(echo "$line" | cut -d'|' -f1)
              VERSION=$(echo "$line" | cut -d'|' -f2)
              aws s3api delete-object --bucket "$TF_BACKEND_BUCKET" --key "$KEY" --version-id "$VERSION" 2>/dev/null || true
            done
            
            # Delete delete markers
            cat /tmp/versions.json | jq -r '.DeleteMarkers[]? | "\(.Key)|\(.VersionId)"' | while read line; do
              KEY=$(echo "$line" | cut -d'|' -f1)
              VERSION=$(echo "$line" | cut -d'|' -f2)
              aws s3api delete-object --bucket "$TF_BACKEND_BUCKET" --key "$KEY" --version-id "$VERSION" 2>/dev/null || true
            done
          fi
          
          echo "Deleting bucket: $TF_BACKEND_BUCKET"
          aws s3api delete-bucket --bucket "$TF_BACKEND_BUCKET" --region "$TF_BACKEND_REGION" || true

      - name: Delete DynamoDB lock table
        run: |
          aws dynamodb delete-table --table-name "$TF_BACKEND_DDB_TABLE" --region "$TF_BACKEND_REGION" || true

      - name: Delete CloudWatch log group
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          aws logs delete-log-group --log-group-name "/aws/eks/citizen-dev/cluster" --region "$AWS_REGION" || true

      - name: Done
        run: |
          echo "Shared infrastructure destroyed"
          echo "Remember: All microservices depending on this will fail!"